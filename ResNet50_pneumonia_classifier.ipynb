{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VeXlHITSdhj"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Author: Siem Russom\n",
        "Date: 10/4/2021\n",
        "Description: ResNet-50 architecture CNN model to classify pneumonia in pediatric\n",
        "            chest x-ray images.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Improt libraries\n",
        "\"\"\"\n",
        "The following libraries are required:\n",
        "\n",
        "  - Tensorflow 2.0: Must be Tensorflow 2.0 since the model required Keras API\n",
        "  - sklearn\n",
        "  - Ipython\n",
        "  - matplotlib\n",
        "  - cv2\n",
        "  - numpy\n",
        "  - seaborn\n",
        "\n",
        "The following are recommnded if working on Google Colab\n",
        "  * os\n",
        "\"\"\"\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import  Conv2D,MaxPooling2D,Activation,Dropout,Flatten,Dense,BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.cm as cm\n",
        "from IPython.display import Image, display\n",
        "from sklearn.metrics import precision_recall_curve, roc_curve, accuracy_score,recall_score,precision_score,confusion_matrix, classification_report\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import  train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import datetime\n",
        "\n",
        "%matplotlib inline\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "pJEZ8FeaS25x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Get dataset and resize such that each image has 224x224 dimension\n",
        "\"\"\"\n",
        "labels = ['PNEUMONIA', 'NORMAL']\n",
        "img_size = 224\n",
        "def get_training_data(data_dir):\n",
        "    data = [] \n",
        "    for label in labels: \n",
        "        path = os.path.join(data_dir, label)\n",
        "        class_num = labels.index(label)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_arr = cv2.imread(os.path.join(path, img),cv2.IMREAD_COLOR )\n",
        "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) \n",
        "                data.append([resized_arr, class_num])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "    return np.array(data)"
      ],
      "metadata": {
        "id": "BD6bu7N9S50c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Split dataset into:\n",
        "  - train: dataset to train model\n",
        "  - test: dataset to test model for accuracy\n",
        "  - val: dataset to validate model and tune parameters\n",
        "\"\"\"\n",
        "train = get_training_data('[REPLACE WITH PATH FOR TRAINING SET]')\n",
        "test = get_training_data('[REPLACE WITH PATH FOR TEST SET]')\n",
        "val = get_training_data('[REPLACE WITH PATH FOR VALIDATION SET]')"
      ],
      "metadata": {
        "id": "0Unc3716S7rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Plot and visualize 2 images\n",
        "\"\"\"\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.imshow(train[1][0], cmap='gray')\n",
        "plt.title(labels[train[1][1]])\n",
        "\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.imshow(train[-1][0], cmap='gray')\n",
        "plt.title(labels[train[-1][1]])"
      ],
      "metadata": {
        "id": "OBB41pcnS9Me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  - x axis - Input to neural network\n",
        "  - y axis - corresponding output\n",
        "\n",
        "  Normalization is a transformation technique to ensure the dataset is on the same \n",
        "  scale. \n",
        "\"\"\"\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for img, label in test:\n",
        "  X.append(img)\n",
        "  y.append(label)\n",
        "\n",
        "for img, label in train:\n",
        "  X.append(img)\n",
        "  y.append(label)\n",
        "\n",
        "for img, label in val:\n",
        "  X.append(img)\n",
        "  y.append(label)\n",
        "\n",
        "\n",
        "#Reshape images \n",
        "X = np.array(X).reshape(-1,img_size,img_size,3)\n",
        "\n",
        "# Normalise images\n",
        "X = X/255\n",
        "y = np.array(y)\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.20, random_state=30)\n",
        "\n",
        "print(\"Shape of x_train: \",x_train.shape)\n",
        "print(\"Shape of y_train: \", y_train.shape)\n",
        "print(\"Shape of x_test: \",x_test.shape)\n",
        "print(\"Shape of y_test: \", y_test.shape)\n",
        "print(\"Shape of x_val: \",x_val.shape)\n",
        "print(\"Shape of y_val: \", y_val.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "lHRcW5PmVOmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Data augmentation is a transformation technique to prevent the model from \n",
        "overfitting, ie learning dataset-specific patterns. We achieve this by slighly \n",
        "modifying each image like flipping, zooming, etc.\n",
        "\"\"\"\n",
        "aug_x_train = ImageDataGenerator(\n",
        "    zoom_range = 0.02, #random zoom 20%\n",
        "    horizontal_flip = True, # random horizontal flip\n",
        "    width_shift_range = 0.1\n",
        "    )\n",
        "aug_x_train.fit(x_train)"
      ],
      "metadata": {
        "id": "slhbqZe4VQhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Define and build model\n",
        "\n",
        "- The architecture used for this particular model is Resnet-50. Resnet or\n",
        "Residual Neural Network is a type of Convolutional Neural Network that was \n",
        "created to solve the problem of exploding and vanishing gradient descent in deeper\n",
        "networks.\n",
        "  Refer to this article for more: https://towardsdatascience.com/resnets-why-do-they-perform-better-than-classic-convnets-conceptual-analysis-6a9c82e06e53\n",
        "\n",
        "- Since a pre-trained model is being used, the base layers will be frozen\n",
        "      with only the top layers being trained. This is done to avoid updating\n",
        "      the weights of the pre-trained model.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "model_d= ResNet50(weights='imagenet',include_top=False, input_shape=(224, 224, 3)) \n",
        "\n",
        "#Freeze all base layers\n",
        "model_d.trainable = False\n",
        "\n",
        "x= model_d.output\n",
        "\n",
        "#Add the necessary top layers\n",
        "x= GlobalAveragePooling2D()(x)\n",
        "x= BatchNormalization()(x)\n",
        "x = Dropout(0.6)(x)\n",
        "x= Dense(512,activation='relu')(x) \n",
        "x= BatchNormalization()(x)\n",
        "x= Dense(325,activation='relu')(x) \n",
        "x= BatchNormalization()(x)\n",
        "x= Dropout(0.70)(x)\n",
        "preds=Dense(1,activation='sigmoid')(x) #FC-layer\n",
        "\n",
        "model=Model(inputs=model_d.input,outputs=preds)\n",
        "\n",
        "\n",
        "lay = []\n",
        "for layer in model.layers:\n",
        "    lay.append(layer.name)\n",
        "    print(layer)\n",
        "\n",
        "ADAM = Adam(learning_rate=0.0001)\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRIC = ['acc']\n",
        "\n",
        "model.compile(optimizer=ADAM, loss=LOSS, metrics=METRIC)\n",
        "es = EarlyStopping(monitor = 'val_loss', patience = 5, verbose = 1)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "QVJOzHziVTee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Tensorboard is a powerful visualization and measurement tool. To use it with\n",
        "this model, uncomment the subsequent two lines. For the purposes of this model,\n",
        "Tensorboard is optional.\n",
        "\"\"\"\n",
        "# logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "# tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "BS = 35 #define batch size\n",
        "EPOCHS = 50 #define the number of epochs\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=BS,\n",
        "                     validation_data = (x_val, y_val),\n",
        "                    epochs = EPOCHS, verbose = 1)"
      ],
      "metadata": {
        "id": "mrGkMb74VUDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model on test data\n",
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "_mD5oHWjVYjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize model accuracy and loss\n",
        "\n",
        "\"\"\" \n",
        "Refer to the link below to learn what model accuracy and loss means\n",
        "(https://machine-learning.paperspace.com/wiki/accuracy-and-loss)\n",
        "\n",
        "\"\"\"\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
        "ax = ax.ravel()\n",
        "\n",
        "for i, met in enumerate(['acc', 'loss']):\n",
        "    ax[i].plot(history.history[met])\n",
        "    ax[i].plot(history.history['val_' + met])\n",
        "    ax[i].set_title('Model {}'.format(met))\n",
        "    ax[i].set_xlabel('epochs')\n",
        "    ax[i].set_ylabel(met)\n",
        "    ax[i].legend(['train', 'val'])"
      ],
      "metadata": {
        "id": "XULvUySDValB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict outputs and plot a Confusion Matrix\n",
        "\"\"\"\n",
        "\n",
        "Refer to the link below to learn what a Confusion Matrix is\n",
        "(https://machine-learning.paperspace.com/wiki/confusion-matrix)\n",
        "\n",
        "\"\"\"\n",
        "pred = model.predict(x_train)\n",
        "precisions, recalls, thresholds = precision_recall_curve(y_train, pred)\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "binary_predictions = []\n",
        "threshold = thresholds[np.argmax(precisions >= 0.80)]\n",
        "for i in predictions:\n",
        "    if i >= threshold:\n",
        "        binary_predictions.append(1)\n",
        "    else:\n",
        "        binary_predictions.append(0) \n",
        "\n",
        "\n",
        "matrix = confusion_matrix(binary_predictions, y_test)\n",
        "plt.figure(figsize=(7, 7))\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(matrix, annot=True, ax = ax)\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted Labels', size=20)\n",
        "ax.set_ylabel('True Labels', size=20)\n",
        "ax.set_title('Confusion Matrix', size=20) \n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)"
      ],
      "metadata": {
        "id": "genj2Q4eVbhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  One challenging problem with Deep Learning models is that they behave like \n",
        "  black boxes. It is incredibly difficult to have a comprehensive understanding\n",
        "  of how each neuron works with other neurons to achive the final output once\n",
        "  trained. \n",
        "\n",
        "  Judging from the accuracy + loss plot and confusion matrix, this model is\n",
        "  incredibly accurate. But without understanding what the model is \"looking\" at,\n",
        "  it would be incredibly risky to deploy the model.\n",
        "\n",
        "  To combat this problem, we will use a Grad-cam(Gradient-weighted Class Activation Mapping).  \n",
        "  Grad-cam uses a target (output) of the last Convolutional layer to produce\n",
        "  a localization map to highlight the important regions of the image, or\n",
        "  what the model is \"looking\" when it produces a prediction. \n",
        "\n",
        "  The code below creates grad-cam, saves image, and display it.\n",
        "\n",
        "  For further explanation and detailed implementation walk-through, refer to\n",
        "  the link below.\n",
        "  (https://keras.io/examples/vision/grad_cam/) \n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "# Image path\n",
        "img_path = \"[REPLACE WITH PATH FOR TEST IMAGE]\"\n",
        "\n",
        "\n",
        "# Load image and convert to tensor of shape (sample,h,w,c)\n",
        "img = tf.keras.utils.load_img (img_path, target_size=(224, 224))\n",
        "img_tensor = tf.keras.utils.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "\n",
        "\n",
        "# Normalize\n",
        "img_tensor /= 255.\n",
        "\n",
        "\n",
        "# store predictions for the image\n",
        "m_pred = model.predict(img_tensor)\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    #create a model that maps the input image to the activations\n",
        "    # of the last conv layer as well as the output predictions\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "\n",
        "    # compute the gradient of the prediction for the image with respect the the last conv layer activation\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    \n",
        "    # get gradient of output neuron with respect to last conv layer output feature map\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # the mean intensity of gradient for specific channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    \n",
        "    # multiply each chanel in feature map array with channel prediction importance,\n",
        "    # then sum across all chanels to generate class activation map\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # normalize heatmap \n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "heatmap = make_gradcam_heatmap(img_tensor, model, 'conv5_block3_out')\n",
        "\n",
        "# Display heatmap\n",
        "\n",
        "\n",
        "def save_and_display_gradcam(img_path, heatmap, alpha=0.4):\n",
        "    # Load image\n",
        "    img = keras.preprocessing.image.load_img(img_path)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "    # Rescale heatmap to a range 0-255\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "    # Use jet colormap to colorize heatmap\n",
        "    jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "    # RGB values of the colormap\n",
        "    jet_colors = jet(np.arange(256))[:, :3]\n",
        "    jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "    # image with RGB colorized heatmap\n",
        "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "    # Superimpose the heatmap \n",
        "    superimposed_img = jet_heatmap * alpha + img\n",
        "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "\n",
        "    superimposed_img.save(\"[REPLACE WITH PATH FOR SAVING IMAGE]\")\n",
        "    # Display heatmap\n",
        "    display(Image(\"[REPLACE WITH THE ABOVE PATH]\", width=255,height=255))\n",
        "\n",
        "\n",
        "save_and_display_gradcam(img_path, heatmap)"
      ],
      "metadata": {
        "id": "4xuZFxT4VdxD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}